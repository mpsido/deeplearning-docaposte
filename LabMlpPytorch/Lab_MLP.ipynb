{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "326d77b0",
   "metadata": {},
   "source": [
    "# Multi Layer Percepron (MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4941630",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03b340ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50e5997",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569c8082",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "The **multi layer perceptron (MLP)** is feedforward neural network composed of successive layers (cf. Figure below).\n",
    "\n",
    "<img src=\"figures/MLP.jpg\" width=\"600px\"/>\n",
    " \n",
    "The dynamics of an MLP is given by the following equations (sample and batch versions):\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{array}{ll}\n",
    "\\textbf{sample $\\boldsymbol{x}$} & \\textbf{batch $\\boldsymbol{X_i}$} \\\\\n",
    "\\begin{cases}\n",
    "\\boldsymbol{a^{[0]}} ~=~ \\boldsymbol{x} & \\\\\n",
    "\\boldsymbol{z^{[l]}} ~=~ \\boldsymbol{W^{[l]}} \\boldsymbol{a^{[l-1]}} + \\boldsymbol{b^{[l]}}, & l = 1, \\dots, L \\\\\n",
    "\\boldsymbol{a^{[l]}} ~=~ \\boldsymbol{\\sigma} \\left( \\boldsymbol{z^{[l]}} \\right), & l = 1, \\dots, L\n",
    "\\end{cases}\n",
    "~&~\n",
    "\\begin{cases}\n",
    "\\boldsymbol{A^{[0]}} ~=~ \\boldsymbol{X_i}\t\\\\\n",
    "\\boldsymbol{Z^{[l]}} ~=~ \\boldsymbol{W^{[l]}} \\boldsymbol{A^{[l-1]}} \\oplus \\boldsymbol{b^{[l]}}, & l = 1, \\dots, L \\\\\n",
    "\\boldsymbol{A^{[l]}} ~=~ \\boldsymbol{\\sigma} \\big( \\boldsymbol{Z^{[l]}} \\big), & l = 1, \\dots, L\n",
    "\\end{cases}\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab415f92",
   "metadata": {},
   "source": [
    "- Define a class `MLP()` which takes a list `[n1, n2, ..., nL]` as parameter and creates an MLP with $L$ layers of $n_i$ neurons each, for $i= 1, \\dots, L$.\n",
    "- Initializes the weights matrices $\\boldsymbol{W^{[l]}}$ and the bias vectors $\\boldsymbol{b^{[l]}}$ randomly from a normal distribution $\\mathcal{N}(0, 1)$ (`torch.normal()`).\n",
    "- The first layer is the input layer and thus has no biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3a10552",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(object):\n",
    "\n",
    "    def __init__(self, sizes):\n",
    "        \"\"\"constructor\"\"\"\n",
    "        \n",
    "        self.num_layers = len(sizes)\n",
    "        self.sizes = sizes\n",
    "        self.biases = [torch.normal(0, 1, size=(n, 1)) \n",
    "                       for n in sizes[1:]] # no bias for 1st layer\n",
    "        self.weights = [torch.normal(0, 1, size=(n2, n1)) \n",
    "                        for n1, n2 in zip(sizes[:-1], sizes[1:])]\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \"\"\"forward pass\"\"\"\n",
    "        \n",
    "        if X.shape[0] != self.sizes[0]:\n",
    "            raise ValueError(\"incorrect input dimension\")\n",
    "        \n",
    "        for W, b in zip(self.weights, self.biases):\n",
    "            X = torch.tanh(torch.mm(W, X) + b)\n",
    "            \n",
    "        return X\n",
    "    \n",
    "    def forward_penultimate(self, X):\n",
    "        \"\"\"forward pass until penultimate layer\"\"\"\n",
    "        \n",
    "        if X.shape[0] != self.sizes[0]:\n",
    "            raise ValueError(\"incorrect input dimension\")\n",
    "        \n",
    "        for W, b in zip(self.weights[:-1], self.biases[:1]):\n",
    "            X = torch.tanh(torch.mm(W, X) + b)\n",
    "            \n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ed07c5",
   "metadata": {},
   "source": [
    "- Add a method `forward(X)` which takes a batch of vectors `X` as inputs (2D tensor), and computes the forward pass of the network on this batch.\n",
    "- For the activation function $\\sigma$, take the `tanh`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7fa9221",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = MLP([10, 30, 30, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "152dbdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand(10, 64) # batch of 64 inputs of size 10 each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "855b5f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = net.forward(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e64e40c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 64])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edac4cd",
   "metadata": {},
   "source": [
    "## Application to the MNIST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f293f4a4",
   "metadata": {},
   "source": [
    "The **MNIST dataset** consists of handwritten digits. The MNIST classification problem consists in predicting the correct digit represented on an image.\n",
    "\n",
    "<img src=\"figures/mnist.png\" width=\"600px\"/>\n",
    "\n",
    "- Load the train and test MNIST datasets using the following commands:\n",
    "```\n",
    "train = datasets.MNIST(root='./data', train=True, download=True, transform=ToTensor())\n",
    "test = datasets.MNIST(root='./data', train=False, download=True, transform=ToTensor())\n",
    "```\n",
    "Each sample consists of a tensor (the image encoded in black and white), and a label (the digit that it represents).\n",
    "- Examine the train and test sets.\n",
    "- Visualize some data samples (tensors) using `plt.imshow()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1950affb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = datasets.MNIST(root='./data', train=True, download=True, transform=ToTensor())\n",
    "test_set = datasets.MNIST(root='./data', train=False, download=True, transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ec6f6e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set), len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d238e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = train_set[47][0]\n",
    "target = train_set[47][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5129ce4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.shape # 3D tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd653d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = sample.view(28, 28) # reshape into 28 x 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "983cce60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x15b157e10>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d85e3f",
   "metadata": {},
   "source": [
    "Each sample is a $28 \\times 28$ 2D-tensor representing a handwritten digit. Note that the sample can be \"flattened\"  into a $28 \\cdot 28 = 784$ 1D-vector using the method `flatten()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1b062d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([784])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_1d = sample.flatten()\n",
    "sample_1d.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b5b9e2",
   "metadata": {},
   "source": [
    "A **dataloader** creates batches of samples from a dataset so that they can be passed into a model.\n",
    "- Create a train and test dataloader using the following commands:\n",
    "```\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=64, shuffle=True)\n",
    "```\n",
    "- Note that dataloaders are not subscriptable.\n",
    "- Try to catch one batch of the dataloader and examine it.\n",
    "- Write a function that reshapes a batch of size $64 \\times 1 \\times 28 \\times 28$ into a tensor of size $784 \\times 64$.<br>\n",
    "(use `torch.squeeze()`, `torch.reshape()`, `torch.flatten()`, `torch.transpose()`, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1a49538",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32ea03d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in train_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06ab2820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 1, 28, 28]), torch.Size([64]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0].shape, b[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0acbe218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([784, 64])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_reshaped = torch.squeeze(b[0])\n",
    "b_reshaped = torch.flatten(b_reshaped, 1, 2)\n",
    "b_reshaped = b_reshaped.transpose(0, 1)\n",
    "b_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ea62b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_batch(b):\n",
    "    \"\"\"reshape batch of tensors\"\"\"\n",
    "    b = torch.squeeze(b)\n",
    "    b = torch.flatten(b, 1, 2).T\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31a13eba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([784, 64])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_reshaped = reshape_batch(b[0])\n",
    "b_reshaped.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bbb26e",
   "metadata": {},
   "source": [
    "- Instantiate a 4-layer MLP with the following characteristics:\n",
    "    - Layer 1 (or input layer): size 784\n",
    "    - Layer 2: size 128\n",
    "    - Layer 3: size 128\n",
    "    - Layer 4 (or output layer): size 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0d5719a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLP([784, 128, 128, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28a679d",
   "metadata": {},
   "source": [
    "- Pass all train samples through your network batch by batch:<br>\n",
    "Create a function `process_data(dataloader, network)` that performs this.\n",
    "- Gather all the outputs into 1 tensor.\n",
    "- Take the argmax of the outputs to obtain the predictions.\n",
    "- Get the classification report associated to your predictions and real labels:<br>\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html\n",
    "- What can you conclude?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e7df52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(dataloader, network):\n",
    "    \"\"\"\n",
    "    Pass a dataloder into a network.\n",
    "    Return targets and predictions.\n",
    "    \"\"\"\n",
    "\n",
    "    all_targets = []\n",
    "    all_predictions = []\n",
    "\n",
    "    for b in dataloader:\n",
    "\n",
    "        # samples and targets\n",
    "        samples = reshape_batch(b[0])\n",
    "        targets = b[1]\n",
    "        all_targets.extend(targets)\n",
    "\n",
    "        # forward pass\n",
    "        outputs = network.forward(samples)\n",
    "        predictions = torch.argmax(outputs, dim=0)\n",
    "        all_predictions.extend(predictions)\n",
    "    \n",
    "    return all_targets, all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a5234f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_targets, all_predictions = process_data(train_loader, mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7aace094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 60000)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_targets), len(all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48f86e6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([tensor(5), tensor(2), tensor(3), tensor(1), tensor(0)],\n",
       " [tensor(0), tensor(0), tensor(0), tensor(0), tensor(1)])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_targets[0:5], all_predictions[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ec85321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train results\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.63      0.16      5923\n",
      "           1       0.08      0.06      0.07      6742\n",
      "           2       0.12      0.09      0.10      5958\n",
      "           3       0.09      0.00      0.00      6131\n",
      "           4       0.04      0.02      0.02      5842\n",
      "           5       0.13      0.03      0.05      5421\n",
      "           6       0.13      0.06      0.08      5918\n",
      "           7       0.07      0.02      0.03      6265\n",
      "           8       0.06      0.01      0.01      5851\n",
      "           9       0.14      0.01      0.03      5949\n",
      "\n",
      "    accuracy                           0.09     60000\n",
      "   macro avg       0.10      0.09      0.06     60000\n",
      "weighted avg       0.10      0.09      0.06     60000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Train results\\n\")\n",
    "print(classification_report(all_targets, all_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "476da6ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test results\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.62      0.15       980\n",
      "           1       0.10      0.07      0.08      1135\n",
      "           2       0.15      0.10      0.12      1032\n",
      "           3       0.03      0.00      0.00      1010\n",
      "           4       0.04      0.01      0.02       982\n",
      "           5       0.15      0.03      0.06       892\n",
      "           6       0.13      0.05      0.08       958\n",
      "           7       0.06      0.01      0.02      1028\n",
      "           8       0.03      0.00      0.01       974\n",
      "           9       0.10      0.01      0.02      1009\n",
      "\n",
      "    accuracy                           0.09     10000\n",
      "   macro avg       0.09      0.09      0.06     10000\n",
      "weighted avg       0.09      0.09      0.06     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_targets, all_predictions = process_data(test_loader, mlp)\n",
    "\n",
    "print(\"Test results\\n\")\n",
    "print(classification_report(all_targets, all_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186f4207",
   "metadata": {},
   "source": [
    "**Oviously, the network is untrained, and thus does not preforms better than chance (10%)!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de58043b",
   "metadata": {},
   "source": [
    "## Train the MLP via Ridge regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6c4c94",
   "metadata": {},
   "source": [
    "- Update the **weights of the last layer** only so that they correspond to the solution of a **Ridge regression**.<br>\n",
    "https://en.wikipedia.org/wiki/Ridge_regression<br>\n",
    "\n",
    "More precisely:\n",
    "- Pass the train set through the network and get the predictions of the penultimate layer<br>\n",
    "(add a method `forward_penultimate()` in the class `MLP`)\n",
    "- Compute the closed-form solution of the Ridge regression:\n",
    "\n",
    "$$\n",
    "{\\displaystyle {\\widehat {\\beta }}_{\\text{ridge}}=(X^{T}X+kI_{p})^{-1}X^{T}y}\n",
    "$$\n",
    "\n",
    "where\n",
    "- $X$ is the <span style=\"color:blue\">row-wise concatenation</span> of the penultimate outputs $\\boldsymbol{a_i}^{[L-1]}$, for $i = 1, \\dots, N$;\n",
    "- $I_{p}$ is the identity matrix of dim $p$;\n",
    "- $k > 0$ is a regularization parameter (e.g. $0.1$);\n",
    "- $y$ is the <span style=\"color:blue\">row-wise concatenation</span> of the 1-hot encoded targets $\\boldsymbol{y_i}$, for $i = 1, \\dots, N$ (`torch.nn.functional.one_hot()`).\n",
    "- **Set weights of the last layer $\\boldsymbol{W}^{[L]}$ as the solution of the Ridge regression.**\n",
    "- **Set the bias of the last layer $\\boldsymbol{b}^{[L]}$ to $\\boldsymbol{0}$.**\n",
    "- Recompute the predictions associated to the train and test sets.\n",
    "- Compute the classification reports.\n",
    "- What can you conclude?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0a33a445",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_penultimate(dataloader, network):\n",
    "    \"\"\"\n",
    "    Pass a dataloder into a network.\n",
    "    Return targets and predictions.\n",
    "    \"\"\"\n",
    "\n",
    "    all_targets = []\n",
    "    all_predictions = []\n",
    "\n",
    "    for b in dataloader:\n",
    "\n",
    "        # samples and targets\n",
    "        samples = reshape_batch(b[0])\n",
    "        targets = b[1]\n",
    "        all_targets.extend(targets)\n",
    "\n",
    "        # forward pass\n",
    "        outputs = network.forward_penultimate(samples)\n",
    "        all_predictions.append(outputs)\n",
    "    \n",
    "    return all_targets, all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b63a8f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_targets, penultimate_outputs = process_data_penultimate(train_loader, mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "caaf3931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 938)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_targets), len(penultimate_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3b438659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 64])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penultimate_outputs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b129bcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ridge_solution(X, y, k):\n",
    "    \n",
    "    targets = torch.tensor(y)\n",
    "    targets = torch.nn.functional.one_hot(targets, num_classes=10)\n",
    "    targets = targets.float()\n",
    "    \n",
    "    outputs = torch.cat(X, dim=1)\n",
    "    outputs = outputs.T\n",
    "    \n",
    "    X_tmp = torch.mm(outputs.T, outputs) + k * torch.eye(outputs.shape[1])\n",
    "    X_tmp = torch.mm(torch.pinverse(X_tmp), outputs.T)\n",
    "    beta = torch.mm(X_tmp, targets)\n",
    "    \n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c92bd977",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = Ridge_solution(penultimate_outputs, all_targets, k=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7ab1dbf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 10])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "21fd7cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_weights = beta.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a8f35d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.weights[-1] = last_weights\n",
    "mlp.biases[-1] = torch.zeros(10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "944e3b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_targets, train_predictions = process_data(train_loader, mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bdcf882d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "65cbfb90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cbccfcd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train results\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.06      0.07      5923\n",
      "           1       0.10      0.06      0.08      6742\n",
      "           2       0.05      0.01      0.02      5958\n",
      "           3       0.12      0.12      0.12      6131\n",
      "           4       0.25      0.10      0.15      5842\n",
      "           5       0.10      0.01      0.01      5421\n",
      "           6       0.02      0.02      0.02      5918\n",
      "           7       0.12      0.10      0.11      6265\n",
      "           8       0.11      0.44      0.18      5851\n",
      "           9       0.10      0.14      0.12      5949\n",
      "\n",
      "    accuracy                           0.11     60000\n",
      "   macro avg       0.11      0.11      0.09     60000\n",
      "weighted avg       0.11      0.11      0.09     60000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Train results\\n\")\n",
    "print(classification_report(train_targets, train_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db95688c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcd2bc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed6d1106",
   "metadata": {},
   "source": [
    "**The results have drastically improved!**\n",
    "- Note that $\\boldsymbol{W}^{[1]}, \\boldsymbol{W}^{[2]}$ are kept untrained (randomly initialized).\n",
    "- Only $\\boldsymbol{W}^{[3]}$ is trained via by a **Ridge regression**.\n",
    "- This suffices to drastically improve the results!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
